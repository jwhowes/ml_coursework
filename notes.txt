NEED TO REDO EVERY FIGURE! (I CHANGED THE CAT IMPUTER)
	- Everything's better now except the forest on the training set
		- The difference is incredibly negligible

TODO:
	- Check specific figure observations
		- 
	- Add intro
	- Take one last look at ROC paragraph
	- Maybe mention in-built cross validation in sklearn

pass_distinction data:
	9485 passes, 2237 distinctions (this is only from those who passed)

Output from grid search:
	Random forest: {'max_features': 8, 'n_estimators': 100}
	Pass fail log: {'Cs': 10, 'max_iter': 100}
	Pass distinction log: {'Cs': 10, 'max_iter': 100}

To fix multiple regressor issue:
	- Add new table/confusion matrix for combined logistic classifier.
	- Mention and disregard possibility of softmax etc.
		- Probably put this in the Logistic Regressor section
		- Difference in performance is extremely slight
		- Difficult to determine superior model

Sampling based off label:
	- Performances essentially identical on traning set
	- Performance of random forest is worse on test set
	- Performance of log regressors better on test set
	- If I do this I'll have to rewrite the conclusion
		- Pretty much back to the old old one (except not so much confidence in regressors over random forests)
		- I expected random forests to do better but they were clearly over-fitted. Given a larger set they may not have been
		- It will be more convincing as regressors are better by every metric
	- Should I do it?
		- It will be a stronger conclusion
		- All other observations will stand (so the answer is probably)