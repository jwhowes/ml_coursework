DATA: () means not sure if relevant. An indent below a note means that info is stored in another table
Module:
	- ID
	- length
	- (start date)

Assessments:
	- module ID
	- presentation ID (not sure what presentation means)
	- type
	- date

Students:
	- gender
	- age range
	- number of previous attempts
	- region
	- disability
	- final result [THIS IS WHAT I'M TRYING TO GUESS]
	- The modules the student is taking
		- student ID
		- module ID
		- presentation ID
		- date's of registration and unregistration
	- Past assessments (very much doubt the model will have access to this)
		- student ID
		- assessment ID
		- date submitted
		- score

VLE info (external resources available to students):
	- site ID
	- module ID
	- assessment ID
	- some other stuff
	- each student's uses
		- date of student's interaction
		- the number of times a student interacted with it that day

GENERAL NOTES:
	The goal is clearly to take a student's information and guess their final result.
	Not sure how much information this model will be given (do they just get student information or do they get some degree of past academic achievements?)
	Think about representation for non-numerical values.

IDEAS:
	I could try just taking a student's information on its own (no extra info from courses etc.). This would be very easy but probably won't get very good results.
	I could try using stratified-sampling (with what field?)
		- Probably one of the aggregate ones, check some correlation stuff
	Think about feature scaling

Data I'll use:
	- Non-aggregate:
		- studentInfo (All fields)
	- Aggregate:
		- studentRegistration (number of courses)
		- studentAssessment (average score)

The four categories issue:
	- Make two groups with two categories in each
		- Need three classifiers
	- Remove 'withdrawn' records and produce a pass/distinction subgroup of pass
		- These are essentially corrupt Data
		- Still need two classifiers if we are to separate pass/distinction
		- Looking at the scatter plot(s) (e.g. avg_score vs final_result), this seems to be confirmed
		- The correlations are much higher if we remove withdrawn records
		- Definitely go for this one but provide functionality for both, so we can compare correlation matrices and accuracy etc.
	- Remove 'withdrawn' records and convert all distinctions to just passes
		- I don't really like this idea
		- Will only need one classifier but it won't give as much information

tables and charts:
	- ROC curves for everything
	- A few charts showing correlations
	- Correlation matrices with and without removing withdrawn rows

pass_distinction data:
    9485 passes, 2237 distinctions (this is only from those who passed)

Output from grid search:
    {'max_features': 8, 'n_estimators': 100}
    RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,       
                        criterion='gini', max_depth=None, max_features=8,       
                        max_leaf_nodes=None, max_samples=None,
                        min_impurity_decrease=0.0, min_impurity_split=None,     
                        min_samples_leaf=1, min_samples_split=2,
                        min_weight_fraction_leaf=0.0, n_estimators=100,
                        n_jobs=None, oob_score=True, random_state=42, verbose=0,
                        warm_start=False)